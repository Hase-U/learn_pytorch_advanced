{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# セマンティックセグメンテーション(PSPNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: gpustat: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "# 実装したネットワークで出力\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup seeds\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1 セマンティックセグメンテーションとは\n",
    "本章では画像処理タスクの１つである，セマンティックセグメンテーションに取り組みながら**PSPNet(Pyramid Scene Parsing Network)**と呼ばれるモデルについて理解する．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### セマンティックセグメンテーションの入出力\n",
    "セマンティックでの入出力の関係は\n",
    "- input : 画像\n",
    "- output : 各ピクセルが所属するクラスのラベル情報\n",
    "\n",
    "出力については**カラーパレット形式**よって表現し，それぞれのラベルに対して予め固有のRGBの値を付与しておきそのRGBの値を元に図示する."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOCデータセット\n",
    "ここではVOCデータセットを用いるが，その中でもセマンティックセグメンテーション用にアノテーションが用意されている画像データのみを使用する．訓練データ1,464枚と検証データ1,449枚を用いる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
