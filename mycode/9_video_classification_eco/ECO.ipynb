{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 動画分類(3DCNN, ECO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: gpustat: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パッケージのimport\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# device = \"cpu\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup seeds\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9-1 動画データに対するディープラーニングとECOの概要\n",
    "Efficient Convolution Network for Online Video Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データをディープラーニングで扱う際の注意点\n",
    "動画を静止画の連なりとして(C,H,W)の三次元のテンソルに対してもう一次元足すだけではうまくいかない．その理由としては時間方向のゆらぎについてカバーできない，つまり同じ動作をしていてもその動作にかかる時間は全く同じであることはないのでそれぞれの動作を別物として処理してしまう．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 動画データをディープラーニングで扱う方法\n",
    "動画データの時間方向でのゆらぎについては静止画における空間方向のゆらぎと同様に考えると，静止画でこのようなゆらぎをCNNで吸収したのと同様に動画データについてもCNNで吸収することが考えることができる．\n",
    "\n",
    "- ```C3D(Convolutional 3D)```：\n",
    "従来の静止画の(H,W)に対して時間軸を足した(H,W,T)の三次元テンソルに対して各チャネルごとに三次元フィルタを作用させる．**時間についての概念をネットワークによって学習していく．**\n",
    "\n",
    "- ```Two-Stream ConvNets```：\n",
    "時間方向の情報を畳み込み層として用意するのではなく，時間の概念を持つ静止画を別で用意する．この時間の概念を表す静止画には**オプティカルフロー(Optical Flow)**と呼ばれる概念を用いる．オプティカルフローとは静止画内で連続するフレーム間で物体がどれだけ移動したかをベクトルで表現したものである．**時間についての概念を先に与えてしまう**\n",
    "\n",
    "\n",
    "時間についての情報をネットワークがデータから学習するC3Dの方が良い気がするが実際には大量のデータが必要であったりネットワークパラメータも膨大になる欠点がある．この欠点を解決するのがECOである．\n",
    "\n",
    "ECOの概要は\n",
    "1. 動画データに前処理を施す．具体的にはフレームごとに動画を分解して大きさの変更や色情報の標準化\n",
    "2. 動画データから取り出したフレーム数$n$のデータをそれぞれ2D Netモジュールに入力する．これによって$(n, 3, 224, 224)$→ $(n, 96, 28, 28)$に変更される．実際にはmini_batchも考えた$(64,n, 96, 28, 28)$とかになる．\n",
    "3. これを三次元畳み込み層に入力することによって一次元の特徴量にする\n",
    "4. さらにこの一次元特徴量を全結合層に入力することによって例えば400次元など想定しているクラスの数の出力にしてあとはソフトマックスなどを用いてクラス分類を行う\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9-2 2D Netモジュール(Inception-v2)の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ECOの2D Netモジュールの概要\n",
    "以下の４つのモジュールによって構成される\n",
    "- BasicConv\n",
    "- InceptionA\n",
    "- InceptionB\n",
    "- InceptionC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BasicConvモジュールの実装\n",
    "通常のCNNと同じ．$(3,224,224)\\rightarrow (192, 28, 28)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv(nn.Module):\n",
    "    '''ECOの2D Netモジュールの最初のモジュール'''\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BasicConv, self).__init__()\n",
    "\n",
    "        self.conv1_7x7_s2 = nn.Conv2d(3, 64, kernel_size=(\n",
    "            7, 7), stride=(2, 2), padding=(3, 3))\n",
    "        self.conv1_7x7_s2_bn = nn.BatchNorm2d(\n",
    "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv1_relu_7x7 = nn.ReLU(inplace=True)\n",
    "        self.pool1_3x3_s2 = nn.MaxPool2d(\n",
    "            kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
    "        self.conv2_3x3_reduce = nn.Conv2d(\n",
    "            64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
    "        self.conv2_3x3_reduce_bn = nn.BatchNorm2d(\n",
    "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv2_relu_3x3_reduce = nn.ReLU(inplace=True)\n",
    "        self.conv2_3x3 = nn.Conv2d(64, 192, kernel_size=(\n",
    "            3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.conv2_3x3_bn = nn.BatchNorm2d(\n",
    "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv2_relu_3x3 = nn.ReLU(inplace=True)\n",
    "        self.pool2_3x3_s2 = nn.MaxPool2d(\n",
    "            kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1_7x7_s2(x)\n",
    "        out = self.conv1_7x7_s2_bn(out)\n",
    "        out = self.conv1_relu_7x7(out)\n",
    "        out = self.pool1_3x3_s2(out)\n",
    "        out = self.conv2_3x3_reduce(out)\n",
    "        out = self.conv2_3x3_reduce_bn(out)\n",
    "        out = self.conv2_relu_3x3_reduce(out)\n",
    "        out = self.conv2_3x3(out)\n",
    "        out = self.conv2_3x3_bn(out)\n",
    "        out = self.conv2_relu_3x3(out)\n",
    "        out = self.pool2_3x3_s2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionA から InceptionCモジュールの実装\n",
    "**```Inception```：フィルタサイズの大きな畳み込み層を使用するのではなく，フィルタサイズの小さな畳み込み層を並列に使用して学習させるパラメータを減らす** .GoogLeNetで考案された手法．\n",
    "\n",
    "- InceptionではSelf-Attention GANでも利用した$1\\times 1$Convolutions(pointwise convolution)を利用する．各並列の塊の一番最初の層に用いられている．大きすぎるチャネルを小さくするために用いられている．\n",
    "\n",
    "\n",
    "- 今回はInceptionのversion 2を用いているので並列処理の３つ目の```self.inception3_```には$3\\times 3$の畳み込み層を二回作用させている．version1では$5\\times 5$を一回作用させていた．\n",
    "\n",
    "\n",
    "- ４つ目の層ではプーリングにマックスプーリングではなくアベレージプーリングが用いられている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionA(nn.Module):\n",
    "    '''InceptionA'''\n",
    "\n",
    "    def __init__(self):\n",
    "        super(InceptionA, self).__init__()\n",
    "\n",
    "        self.inception_3a_1x1 = nn.Conv2d(\n",
    "            192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
    "        self.inception_3a_1x1_bn = nn.BatchNorm2d(\n",
    "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.inception_3a_relu_1x1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.inception_3a_3x3_reduce = nn.Conv2d(\n",
    "            192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
    "        self.inception_3a_3x3_reduce_bn = nn.BatchNorm2d(\n",
    "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.inception_3a_relu_3x3_reduce = nn.ReLU(inplace=True)\n",
    "        self.inception_3a_3x3 = nn.Conv2d(\n",
    "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.inception_3a_3x3_bn = nn.BatchNorm2d(\n",
    "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.inception_3a_relu_3x3 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.inception_3a_double_3x3_reduce = nn.Conv2d(\n",
    "            192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
    "        self.inception_3a_double_3x3_reduce_bn = nn.BatchNorm2d(\n",
    "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.inception_3a_relu_double_3x3_reduce = nn.ReLU(inplace=True)\n",
    "        self.inception_3a_double_3x3_1 = nn.Conv2d(\n",
    "            64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.inception_3a_double_3x3_1_bn = nn.BatchNorm2d(\n",
    "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.inception_3a_relu_double_3x3_1 = nn.ReLU(inplace=True)\n",
    "        self.inception_3a_double_3x3_2 = nn.Conv2d(\n",
    "            96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.inception_3a_double_3x3_2_bn = nn.BatchNorm2d(\n",
    "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.inception_3a_relu_double_3x3_2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.inception_3a_pool = nn.AvgPool2d(\n",
    "            kernel_size=3, stride=1, padding=1)\n",
    "        self.inception_3a_pool_proj = nn.Conv2d(\n",
    "            192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
    "        self.inception_3a_pool_proj_bn = nn.BatchNorm2d(\n",
    "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.inception_3a_relu_pool_proj = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out1 = self.inception_3a_1x1(x)\n",
    "        out1 = self.inception_3a_1x1_bn(out1)\n",
    "        out1 = self.inception_3a_relu_1x1(out1)\n",
    "\n",
    "        out2 = self.inception_3a_3x3_reduce(x)\n",
    "        out2 = self.inception_3a_3x3_reduce_bn(out2)\n",
    "        out2 = self.inception_3a_relu_3x3_reduce(out2)\n",
    "        out2 = self.inception_3a_3x3(out2)\n",
    "        out2 = self.inception_3a_3x3_bn(out2)\n",
    "        out2 = self.inception_3a_relu_3x3(out2)\n",
    "\n",
    "        out3 = self.inception_3a_double_3x3_reduce(x)\n",
    "        out3 = self.inception_3a_double_3x3_reduce_bn(out3)\n",
    "        out3 = self.inception_3a_relu_double_3x3_reduce(out3)\n",
    "        out3 = self.inception_3a_double_3x3_1(out3)\n",
    "        out3 = self.inception_3a_double_3x3_1_bn(out3)\n",
    "        out3 = self.inception_3a_relu_double_3x3_1(out3)\n",
    "        out3 = self.inception_3a_double_3x3_2(out3)\n",
    "        out3 = self.inception_3a_double_3x3_2_bn(out3)\n",
    "        out3 = self.inception_3a_relu_double_3x3_2(out3)\n",
    "\n",
    "        out4 = self.inception_3a_pool(x)\n",
    "        out4 = self.inception_3a_pool_proj(out4)\n",
    "        out4 = self.inception_3a_pool_proj_bn(out4)\n",
    "        out4 = self.inception_3a_relu_pool_proj(out4)\n",
    "\n",
    "        \"\"\"並列に処理させた後に結合する\"\"\"\n",
    "        outputs = [out1, out2, out3, out4]   \n",
    "\n",
    "        return torch.cat(outputs, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionB(nn.Module):\n",
    "    '''InceptionB'''\n",
    "\n",
    "    def __init__(self):\n",
    "        super(InceptionB, self).__init__()\n",
    "        \n",
    "        self.inception_3b_1x1 = nn.Conv2d(\n",
    "            256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
    "        self.inception_3b_1x1_bn = nn.BatchNorm2d(\n",
    "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.inception_3b_relu_1x1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.inception_3b_3x3_reduce = nn.Conv2d(\n",
    "            256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
    "        self.inception_3b_3x3_reduce_bn = nn.BatchNorm2d(\n",
    "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.inception_3b_relu_3x3_reduce = nn.ReLU(inplace=True)\n",
    "        self.inception_3b_3x3 = nn.Conv2d(\n",
    "            64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.inception_3b_3x3_bn = nn.BatchNorm2d(\n",
    "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.inception_3b_relu_3x3 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.inception_3b_double_3x3_reduce = nn.Conv2d(\n",
    "            256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
    "        self.inception_3b_double_3x3_reduce_bn = nn.BatchNorm2d(\n",
    "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.inception_3b_relu_double_3x3_reduce = nn.ReLU(inplace=True)\n",
    "        self.inception_3b_double_3x3_1 = nn.Conv2d(\n",
    "            64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.inception_3b_double_3x3_1_bn = nn.BatchNorm2d(\n",
    "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.inception_3b_relu_double_3x3_1 = nn.ReLU(inplace=True)\n",
    "        self.inception_3b_double_3x3_2 = nn.Conv2d(\n",
    "            96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.inception_3b_double_3x3_2_bn = nn.BatchNorm2d(\n",
    "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.inception_3b_relu_double_3x3_2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.inception_3b_pool = nn.AvgPool2d(\n",
    "            kernel_size=3, stride=1, padding=1)\n",
    "        self.inception_3b_pool_proj = nn.Conv2d(\n",
    "            256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
    "        self.inception_3b_pool_proj_bn = nn.BatchNorm2d(\n",
    "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.inception_3b_relu_pool_proj = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out1 = self.inception_3b_1x1(x)\n",
    "        out1 = self.inception_3b_1x1_bn(out1)\n",
    "        out1 = self.inception_3b_relu_1x1(out1)\n",
    "\n",
    "        out2 = self.inception_3b_3x3_reduce(x)\n",
    "        out2 = self.inception_3b_3x3_reduce_bn(out2)\n",
    "        out2 = self.inception_3b_relu_3x3_reduce(out2)\n",
    "        out2 = self.inception_3b_3x3(out2)\n",
    "        out2 = self.inception_3b_3x3_bn(out2)\n",
    "        out2 = self.inception_3b_relu_3x3(out2)\n",
    "\n",
    "        out3 = self.inception_3b_double_3x3_reduce(x)\n",
    "        out3 = self.inception_3b_double_3x3_reduce_bn(out3)\n",
    "        out3 = self.inception_3b_relu_double_3x3_reduce(out3)\n",
    "        out3 = self.inception_3b_double_3x3_1(out3)\n",
    "        out3 = self.inception_3b_double_3x3_1_bn(out3)\n",
    "        out3 = self.inception_3b_relu_double_3x3_1(out3)\n",
    "        out3 = self.inception_3b_double_3x3_2(out3)\n",
    "        out3 = self.inception_3b_double_3x3_2_bn(out3)\n",
    "        out3 = self.inception_3b_relu_double_3x3_2(out3)\n",
    "\n",
    "        out4 = self.inception_3b_pool(x)\n",
    "        out4 = self.inception_3b_pool_proj(out4)\n",
    "        out4 = self.inception_3b_pool_proj_bn(out4)\n",
    "        out4 = self.inception_3b_relu_pool_proj(out4)\n",
    "\n",
    "        outputs = [out1, out2, out3, out4]\n",
    "\n",
    "        return torch.cat(outputs, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "InceptionCではA,Bとは異なり並列処理は行わない．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionC(nn.Module):\n",
    "    '''InceptionC'''\n",
    "\n",
    "    def __init__(self):\n",
    "        super(InceptionC, self).__init__()\n",
    "\n",
    "        self.inception_3c_double_3x3_reduce = nn.Conv2d(\n",
    "            320, 64, kernel_size=(1, 1), stride=(1, 1))\n",
    "        self.inception_3c_double_3x3_reduce_bn = nn.BatchNorm2d(\n",
    "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.inception_3c_relu_double_3x3_reduce = nn.ReLU(inplace=True)\n",
    "        self.inception_3c_double_3x3_1 = nn.Conv2d(\n",
    "            64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.inception_3c_double_3x3_1_bn = nn.BatchNorm2d(\n",
    "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.inception_3c_relu_double_3x3_1 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.inception_3c_double_3x3_reduce(x)\n",
    "        out = self.inception_3c_double_3x3_reduce_bn(out)\n",
    "        out = self.inception_3c_relu_double_3x3_reduce(out)\n",
    "        out = self.inception_3c_double_3x3_1(out)\n",
    "        out = self.inception_3c_double_3x3_1_bn(out)\n",
    "        out = self.inception_3c_relu_double_3x3_1(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上をまとめて2DNetモジュールクラスを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECO_2D(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ECO_2D,self).__init__()\n",
    "        \n",
    "        self.basic_conv = BasicConv()\n",
    "        self.inception_a = InceptionA()\n",
    "        self.inception_b = InceptionB()\n",
    "        self.inception_c = InceptionC()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.basic_conv(x)\n",
    "        out = self.inception_a(out)\n",
    "        out = self.inception_b(out)\n",
    "        out = self.inception_c(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ECO_2D(\n",
       "  (basic_conv): BasicConv(\n",
       "    (conv1_7x7_s2): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (conv1_7x7_s2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1_relu_7x7): ReLU(inplace=True)\n",
       "    (pool1_3x3_s2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (conv2_3x3_reduce): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv2_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2_relu_3x3_reduce): ReLU(inplace=True)\n",
       "    (conv2_3x3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2_3x3_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2_relu_3x3): ReLU(inplace=True)\n",
       "    (pool2_3x3_s2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  )\n",
       "  (inception_a): InceptionA(\n",
       "    (inception_3a_1x1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (inception_3a_1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (inception_3a_relu_1x1): ReLU(inplace=True)\n",
       "    (inception_3a_3x3_reduce): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (inception_3a_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (inception_3a_relu_3x3_reduce): ReLU(inplace=True)\n",
       "    (inception_3a_3x3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (inception_3a_3x3_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (inception_3a_relu_3x3): ReLU(inplace=True)\n",
       "    (inception_3a_double_3x3_reduce): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (inception_3a_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (inception_3a_relu_double_3x3_reduce): ReLU(inplace=True)\n",
       "    (inception_3a_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (inception_3a_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (inception_3a_relu_double_3x3_1): ReLU(inplace=True)\n",
       "    (inception_3a_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (inception_3a_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (inception_3a_relu_double_3x3_2): ReLU(inplace=True)\n",
       "    (inception_3a_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (inception_3a_pool_proj): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (inception_3a_pool_proj_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (inception_3a_relu_pool_proj): ReLU(inplace=True)\n",
       "  )\n",
       "  (inception_b): InceptionB(\n",
       "    (inception_3b_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (inception_3b_1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (inception_3b_relu_1x1): ReLU(inplace=True)\n",
       "    (inception_3b_3x3_reduce): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (inception_3b_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (inception_3b_relu_3x3_reduce): ReLU(inplace=True)\n",
       "    (inception_3b_3x3): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (inception_3b_3x3_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (inception_3b_relu_3x3): ReLU(inplace=True)\n",
       "    (inception_3b_double_3x3_reduce): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (inception_3b_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (inception_3b_relu_double_3x3_reduce): ReLU(inplace=True)\n",
       "    (inception_3b_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (inception_3b_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (inception_3b_relu_double_3x3_1): ReLU(inplace=True)\n",
       "    (inception_3b_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (inception_3b_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (inception_3b_relu_double_3x3_2): ReLU(inplace=True)\n",
       "    (inception_3b_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "    (inception_3b_pool_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (inception_3b_pool_proj_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (inception_3b_relu_pool_proj): ReLU(inplace=True)\n",
       "  )\n",
       "  (inception_c): InceptionC(\n",
       "    (inception_3c_double_3x3_reduce): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (inception_3c_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (inception_3c_relu_double_3x3_reduce): ReLU(inplace=True)\n",
       "    (inception_3c_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (inception_3c_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (inception_3c_relu_double_3x3_1): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 動作確認\n",
    "net = ECO_2D()\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(\"./tbX/\")\n",
    "\n",
    "batch_size = 1\n",
    "dummy_img = torch.rand(batch_size, 3, 224, 224)\n",
    "\n",
    "writer.add_graph(net, (dummy_img, ))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9-3 3D Netモジュール(3DCNN)の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ECOの3D Netモジュールの概要\n",
    "3D Netモジュールでは$(16, 96, 28, 28)\\rightarrow (512)$とする.\n",
    "\n",
    "3D Netモジュールの構成は以下である\n",
    "1. テンソルの順序を入れ替える$(16, 96, 28, 28)\\rightarrow(96, 16, 28, 28)$に変更する．三次元フィルタを用いるので(T,H,W)の順で情報を持っていた方が扱いやすい\n",
    "2. ResNetの三次元フィルタに複数回入力する\n",
    "3. 三次元アベレージプーリングを作用させる．ここでは全結合層の代わりにアベレージプーリングを入力テンソルと同じサイズにして作用させる．このように計算量を減らしたり過学習を避けるために全結合層の代わりに用いられるアベレージプーリング層を**Global Average Pooling**と言われる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet_3D_3 の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
