{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ganによる異常検知"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: gpustat: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パッケージのimport\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-1 GANによる異常画像検知のメカニズム"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ganを用いた異常画像検知の必要性\n",
    "異常画像検知は医療の現場や，製造業の生産ラインで利用される．従来では熟練者の経験で行われていたものをマシンに行わせる．\n",
    "従来のルールベースの手法ではうまくいかなったものがディープラーニングの導入によって補助・代替できる可能性がある．\n",
    "\n",
    "**しかしディープラーニングを用いた異常画像検知の問題点としては正常画像の数に対して異常画像の数が圧倒的に少ないことである．** そこで本節では正常画像のみでディープラーニングを行って異常画像を検出できるアルゴリズムの構築することに取り組む．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AnoGANの概要\n",
    "最も自然な考えとしては正常画像のみを生成するGANを構築して，そのDiscriminatorに対してテストしたい画像を入力することで教師画像か偽画像かを判断させる方法で，教師画像と判断されればこれは正常画像であり，偽画像と判断されればこれは異常画像として検知される．しかしこのような方法では実際にはうまくいかないらしい．\n",
    "\n",
    "実際にはGeneratorも用いて異常検知させる．大まかには以下の手順で行う．\n",
    "1. **まず通常のGANと同様に正常画像のみでGANを構築する．**\n",
    "2. **Generatorに入力する生成ノイズzの中で最もテストしたい画像に近い画像を生成できるzを決定する．**\n",
    "3. **その決定したzを用いて生成した画像とテストしたい画像がどれくらい似ているかで異常検知を行う．**\n",
    "\n",
    "次節ではこれらの手順に加えて以下についても理解していく．\n",
    "- Discriminatorはどこで用いるのか\n",
    "- 生成ノイズzの最適値はどのように決定するのか\n",
    "- 生成画像とテスト画像の似ている度合いはどのように判断するのか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-2 AnoGANの実装と異常検知の実施"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCGANの学習\n",
    "AnoGANのGANには前節で実装したDCGANを用いる．\n",
    "\n",
    "DCGANに対してAnoGAN用にDiscriminatorの最後の出力の１つ手前の層の特徴量も出力するように変更する．\n",
    "この特徴量を用いて生成ノイズの最適値を求める．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, z_dim = 20, image_size=64):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # ここで out_channels = image_size*8に特別な意味は？\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(z_dim, image_size*8, kernel_size=4, stride=1),\n",
    "            nn.BatchNorm2d(image_size*8),\n",
    "            nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(image_size*8, image_size*4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(image_size*4),\n",
    "            nn.ReLU(inplace=True))\n",
    "            \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(image_size*4, image_size*2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(image_size*2),\n",
    "            nn.ReLU(inplace=True))\n",
    "              \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(image_size*2, image_size, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(image_size),\n",
    "            nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.last = nn.Sequential(\n",
    "            nn.ConvTranspose2d(image_size, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh())\n",
    "        # 白黒なので出力は1チャネル\n",
    "        \n",
    "        \n",
    "    def forward(self, z):\n",
    "        out = self.layer1(z)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.last(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, z_dim=20, image_size=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, image_size, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(image_size, image_size*2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(image_size*2, image_size*4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(image_size*4, image_size*8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "        \n",
    "        self.last = nn.Conv2d(image_size*8, 1, kernel_size=4, stride=1)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        \n",
    "        \"\"\"\n",
    "        生成ノイズzを決定するための特徴量を出力する\n",
    "        \"\"\"\n",
    "        feature = out\n",
    "        feature = feature.view(f)\n",
    "        \n",
    "        out = self.last(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
