{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SSD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN6OSg1mYr3prL1M11LHhMA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hase-U/learn_pytorch_advanced/blob/master/mycode/2_objectdetection/SSD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrTttss3fI8W",
        "colab_type": "text"
      },
      "source": [
        "# 物体検出\n",
        "commit用\n",
        "\n",
        "```mycode/2_objectdetection/```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHkJ_EzfVH4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import time\n",
        "from google.colab import files\n",
        "import xml.etree.ElementTree as ET \n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "\n",
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oo8TEKeVI4G",
        "colab_type": "text"
      },
      "source": [
        "## 2-1物体検出とは\n",
        "**バウンディングボックス(bounding box)：**物体の位置を表す枠\n",
        "\n",
        "インプット：画像\n",
        "\n",
        "アウトプット：\n",
        "- 画像のどこに物体が存在するかを示すバウンディングボックスの位置と大きさ情報\n",
        "- 各バウンディングボックスに何が写っているか\n",
        "- その検出に対する確信度"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FbWJKDTpM06",
        "colab_type": "text"
      },
      "source": [
        "### SSDの流れ\n",
        "デフォルトボックスの数がN, クラスが背景を入れてO+1の場合\n",
        "1. 画像のリサイズ\n",
        "2. デフォルトボックスを準備(N個)\n",
        "3. 画像をSSDネットワークに入力(出力 N$\\times$(O+1+4(オフセット)))\n",
        "4. 信頼度上位のデフォルトボックスを抽出\n",
        "5. オフセット情報による修正と被りの除去\n",
        "6. 閾値を超える信頼度のもののみを最終出力にする"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXk6MwgJsWWM",
        "colab_type": "text"
      },
      "source": [
        "## 2-2 Datasetの実装\n",
        "データセットがめちゃ大きくてダウンロードに15分毎回かかるから他にいい方法がないか以下を試した\n",
        "- ```!wget```して解凍\n",
        "- ファイルをアップロード\n",
        "- Google drive でマウント\n",
        "\n",
        "多分```!wget```を毎回するのが一番早いと思われ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3CrBpElfXOY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2c6b948e-72f8-4183-ea83-6c4a72640bda"
      },
      "source": [
        "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n",
        "!tar xf VOCtrainval_11-May-2012.tar"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-03 11:20:33--  http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n",
            "Resolving host.robots.ox.ac.uk (host.robots.ox.ac.uk)... 129.67.94.152\n",
            "Connecting to host.robots.ox.ac.uk (host.robots.ox.ac.uk)|129.67.94.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1999639040 (1.9G) [application/x-tar]\n",
            "Saving to: ‘VOCtrainval_11-May-2012.tar’\n",
            "\n",
            "VOCtrainval_11-May- 100%[===================>]   1.86G  77.7MB/s    in 25s     \n",
            "\n",
            "2020-04-03 11:25:19 (76.3 MB/s) - ‘VOCtrainval_11-May-2012.tar’ saved [1999639040/1999639040]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTbLdJ2lwb1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9_UqTCYF1_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2fZsIDoRunx",
        "colab_type": "text"
      },
      "source": [
        "### 画像データ、アノテーションデータへのファイルパスリストを作成\n",
        "**アノテーション**：正解データ。今回で言えば画像のどこに何があるかというバウンディングボックスの情報を指す"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFlCDsGXF3db",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 画像データとアノテーションデータへのファイルパスリストを作成する\n",
        "\n",
        "def make_datapath_list(rootpath):\n",
        "\n",
        "  # 画像ファイルとアノテーションファイルへのパスのテンプレートを作成\n",
        "  imgpath_template = osp.join(rootpath, \"JPEGImages\", \"%s.jpg\")\n",
        "  annopath_template = osp.join(rootpath, \"Annotations\", \"%s.xml\")\n",
        "\n",
        "  #訓練と検証、それぞれのファイルのIDを取得する\n",
        "  train_id_names = osp.join(rootpath+\"ImageSets/Main/train.txt\")\n",
        "  val_id_names = osp.join(rootpath+\"ImageSets/Main/val.txt\")\n",
        "\n",
        "  # 訓練データの画像ファイルとアノテーションファイルへのパスリストを作成\n",
        "  train_img_list = list()\n",
        "  train_anno_list = list()\n",
        "\n",
        "  for line in open(train_id_names):\n",
        "    file_id = line.strip()\n",
        "    img_path = (imgpath_template % file_id) #画像パス\n",
        "    anno_path = (annopath_template % file_id) #アノテーションのパス\n",
        "    train_img_list.append(img_path)\n",
        "    train_anno_list.append(anno_path)\n",
        "\n",
        "    #検証データの画像ファイルとアノテーションファイルへのパスリストの作成\n",
        "    val_img_list = list()\n",
        "    val_anno_list = list()\n",
        "\n",
        "  for line in open(val_id_names):\n",
        "    # print(file_id)\n",
        "    file_id = line.strip()\n",
        "    img_path = (imgpath_template % file_id) #画像パス\n",
        "    anno_path = (annopath_template % file_id) #アノテーションのパス\n",
        "    val_img_list.append(img_path)\n",
        "    val_anno_list.append(anno_path)   \n",
        "  \n",
        "  \"\"\"\n",
        "  それぞれで何が起きてるか確認用\n",
        "  \"\"\"\n",
        "  # print(\"line : \", line)\n",
        "  # print(\"file_id : \",file_id)\n",
        "  # print(\"annopath_template : \",annopath_template)\n",
        "  # print(\"anno_path : \",anno_path)\n",
        "\n",
        "  return train_img_list, train_anno_list, val_img_list, val_anno_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7GLOlX1WYNk",
        "colab_type": "code",
        "outputId": "43b156bb-0be8-4326-e769-030af14ba4d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# 動作確認\n",
        "rootpath = \"./VOCdevkit/VOC2012/\"\n",
        "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(rootpath)\n",
        "\n",
        "print(\"----------------------------\")\n",
        "\n",
        "print(train_img_list[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "line :  2011_003275\n",
            "\n",
            "file_id :  2011_003275\n",
            "annopath_template :  ./VOCdevkit/VOC2012/Annotations/%s.xml\n",
            "anno_path :  ./VOCdevkit/VOC2012/Annotations/2011_003275.xml\n",
            "----------------------------\n",
            "./VOCdevkit/VOC2012/JPEGImages/2008_000008.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4io6AIOIUyF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SXsN4EjyKGF",
        "colab_type": "text"
      },
      "source": [
        "### xml形式のアノテーションデータをリストに変換"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TInC6daxyJqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# XML形式をリスト形式に変換する\n",
        "\n",
        "class Anno_xml2list(object):\n",
        "  #objectは今から入力する画像の中に存在し得る物体のリスト\n",
        "\n",
        "\n",
        "  def __init__(self, classes):\n",
        "    self.classes = classes\n",
        "\n",
        "  def __call__(self, xml_path, width, height):\n",
        "\n",
        "    # 画像内の全ての物体のアノテーションをこのリストに格納する\n",
        "    res = []\n",
        "\n",
        "    # xmlファイルを読み込む\n",
        "    xml = ET.parse(xml_path).getroot()\n",
        "\n",
        "    # 画像内にある物体(object)の数だけループする\n",
        "    for obj in xml.iter(\"object\"):\n",
        "      \n",
        "      #アノテーションで検知がdifficultに設定されているものは除外\n",
        "      difficult = int(obj.find(\"difficult\").text)\n",
        "      if difficult == 1:\n",
        "        continue\n",
        "      \n",
        "      #１つの物体に対するアノテーションを格納するリスト\n",
        "      bndbox = []\n",
        "\n",
        "      name = obj.find(\"name\").text.lower().strip() #小文字揃えにして改行、空白をのぞいてる\n",
        "      bbox = obj.find(\"bndbox\") #バウンディボックスの情報\n",
        "\n",
        "      # アノテーションのxmin, ymin, xmax, ymaxを取得して、[0,1]で正規化\n",
        "      pts = [\"xmin\", \"ymin\", \"xmax\", \"ymax\"]\n",
        "\n",
        "      for pt in pts:\n",
        "        #VOCは原点が(1,1)なので(0,0)に\n",
        "        cur_pixel = int(bbox.find(pt).text) - 1\n",
        "\n",
        "        # 幅、高さで正規化\n",
        "        if pt ==\"xmin\" or pt == \"xmax\": \n",
        "          cur_pixel /= width   \n",
        "        else:\n",
        "          cur_pixel /= height\n",
        "\n",
        "        bndbox.append(cur_pixel)\n",
        "      \n",
        "      # アノテーションのクラス名のindexを取得して追加\n",
        "      label_idx = self.classes.index(name)\n",
        "      bndbox.append(label_idx)\n",
        "\n",
        "      #　resに[\"xmin\", \"ymin\", \"xmax\", \"ymax\", \"label_idx\"]を加える\n",
        "      res += [bndbox]\n",
        "\n",
        "    return np.array(res)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7G8fIXIWTTH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2b3b22c6-17e7-45e7-80a9-14af4cc32c05"
      },
      "source": [
        "#動作確認\n",
        "voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
        "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
        "               'cow', 'diningtable', 'dog', 'horse',\n",
        "               'motorbike', 'person', 'pottedplant',\n",
        "               'sheep', 'sofa', 'train', 'tvmonitor']\n",
        "\n",
        "transform_anno = Anno_xml2list(voc_classes)\n",
        "\n",
        "#画像の読み込み\n",
        "ind = 1\n",
        "image_file_path = val_img_list[1]\n",
        "img = cv2.imread(image_file_path)\n",
        "height , width, channlels = img.shape\n",
        "\n",
        "transform_anno(val_anno_list[ind], width, height)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.09      ,  0.03003003,  0.998     ,  0.996997  , 18.        ],\n",
              "       [ 0.122     ,  0.56756757,  0.164     ,  0.72672673, 14.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiK8kKw02mYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVHqlzUa3EzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}